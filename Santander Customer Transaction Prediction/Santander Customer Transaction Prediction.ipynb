{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10385,"databundleVersionId":298493,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-28T08:31:09.790904Z","iopub.execute_input":"2024-10-28T08:31:09.791286Z","iopub.status.idle":"2024-10-28T08:31:10.187803Z","shell.execute_reply.started":"2024-10-28T08:31:09.791247Z","shell.execute_reply":"2024-10-28T08:31:10.186666Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/santander-customer-transaction-prediction/sample_submission.csv\n/kaggle/input/santander-customer-transaction-prediction/train.csv\n/kaggle/input/santander-customer-transaction-prediction/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/train.csv')\ntest=pd.read_csv('/kaggle/input/santander-customer-transaction-prediction/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:11.797142Z","iopub.execute_input":"2024-10-28T08:31:11.797958Z","iopub.status.idle":"2024-10-28T08:31:30.504855Z","shell.execute_reply.started":"2024-10-28T08:31:11.797914Z","shell.execute_reply":"2024-10-28T08:31:30.504018Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:45.187270Z","iopub.execute_input":"2024-10-28T08:31:45.187636Z","iopub.status.idle":"2024-10-28T08:31:45.225653Z","shell.execute_reply.started":"2024-10-28T08:31:45.187600Z","shell.execute_reply":"2024-10-28T08:31:45.224759Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n\n     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n\n   var_196  var_197  var_198  var_199  \n0   7.8784   8.5635  12.7803  -1.0914  \n1   8.1267   8.7889  18.3560   1.9518  \n2  -6.5213   8.2675  14.7222   0.3965  \n3  -2.9275  10.2922  17.9697  -8.9996  \n4   3.9267   9.5031  17.9974  -8.8104  \n\n[5 rows x 202 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>target</th>\n      <th>var_0</th>\n      <th>var_1</th>\n      <th>var_2</th>\n      <th>var_3</th>\n      <th>var_4</th>\n      <th>var_5</th>\n      <th>var_6</th>\n      <th>var_7</th>\n      <th>...</th>\n      <th>var_190</th>\n      <th>var_191</th>\n      <th>var_192</th>\n      <th>var_193</th>\n      <th>var_194</th>\n      <th>var_195</th>\n      <th>var_196</th>\n      <th>var_197</th>\n      <th>var_198</th>\n      <th>var_199</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>0</td>\n      <td>8.9255</td>\n      <td>-6.7863</td>\n      <td>11.9081</td>\n      <td>5.0930</td>\n      <td>11.4607</td>\n      <td>-9.2834</td>\n      <td>5.1187</td>\n      <td>18.6266</td>\n      <td>...</td>\n      <td>4.4354</td>\n      <td>3.9642</td>\n      <td>3.1364</td>\n      <td>1.6910</td>\n      <td>18.5227</td>\n      <td>-2.3978</td>\n      <td>7.8784</td>\n      <td>8.5635</td>\n      <td>12.7803</td>\n      <td>-1.0914</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>0</td>\n      <td>11.5006</td>\n      <td>-4.1473</td>\n      <td>13.8588</td>\n      <td>5.3890</td>\n      <td>12.3622</td>\n      <td>7.0433</td>\n      <td>5.6208</td>\n      <td>16.5338</td>\n      <td>...</td>\n      <td>7.6421</td>\n      <td>7.7214</td>\n      <td>2.5837</td>\n      <td>10.9516</td>\n      <td>15.4305</td>\n      <td>2.0339</td>\n      <td>8.1267</td>\n      <td>8.7889</td>\n      <td>18.3560</td>\n      <td>1.9518</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>0</td>\n      <td>8.6093</td>\n      <td>-2.7457</td>\n      <td>12.0805</td>\n      <td>7.8928</td>\n      <td>10.5825</td>\n      <td>-9.0837</td>\n      <td>6.9427</td>\n      <td>14.6155</td>\n      <td>...</td>\n      <td>2.9057</td>\n      <td>9.7905</td>\n      <td>1.6704</td>\n      <td>1.6858</td>\n      <td>21.6042</td>\n      <td>3.1417</td>\n      <td>-6.5213</td>\n      <td>8.2675</td>\n      <td>14.7222</td>\n      <td>0.3965</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>0</td>\n      <td>11.0604</td>\n      <td>-2.1518</td>\n      <td>8.9522</td>\n      <td>7.1957</td>\n      <td>12.5846</td>\n      <td>-1.8361</td>\n      <td>5.8428</td>\n      <td>14.9250</td>\n      <td>...</td>\n      <td>4.4666</td>\n      <td>4.7433</td>\n      <td>0.7178</td>\n      <td>1.4214</td>\n      <td>23.0347</td>\n      <td>-1.2706</td>\n      <td>-2.9275</td>\n      <td>10.2922</td>\n      <td>17.9697</td>\n      <td>-8.9996</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>0</td>\n      <td>9.8369</td>\n      <td>-1.4834</td>\n      <td>12.8746</td>\n      <td>6.6375</td>\n      <td>12.2772</td>\n      <td>2.4486</td>\n      <td>5.9405</td>\n      <td>19.2514</td>\n      <td>...</td>\n      <td>-1.4905</td>\n      <td>9.5214</td>\n      <td>-0.1508</td>\n      <td>9.1942</td>\n      <td>13.2876</td>\n      <td>-1.5121</td>\n      <td>3.9267</td>\n      <td>9.5031</td>\n      <td>17.9974</td>\n      <td>-8.8104</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 202 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:46.288072Z","iopub.execute_input":"2024-10-28T08:31:46.288928Z","iopub.status.idle":"2024-10-28T08:31:46.294679Z","shell.execute_reply.started":"2024-10-28T08:31:46.288884Z","shell.execute_reply":"2024-10-28T08:31:46.293721Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(200000, 202)"},"metadata":{}}]},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:47.550694Z","iopub.execute_input":"2024-10-28T08:31:47.551502Z","iopub.status.idle":"2024-10-28T08:31:47.557777Z","shell.execute_reply.started":"2024-10-28T08:31:47.551459Z","shell.execute_reply":"2024-10-28T08:31:47.556724Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['ID_code', 'target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4',\n       'var_5', 'var_6', 'var_7',\n       ...\n       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n       'var_196', 'var_197', 'var_198', 'var_199'],\n      dtype='object', length=202)"},"metadata":{}}]},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:48.656399Z","iopub.execute_input":"2024-10-28T08:31:48.657124Z","iopub.status.idle":"2024-10-28T08:31:48.673059Z","shell.execute_reply.started":"2024-10-28T08:31:48.657088Z","shell.execute_reply":"2024-10-28T08:31:48.672003Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"target\n0    179902\n1     20098\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"\ntrain.isna().sum()*100/len(train)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:49.974826Z","iopub.execute_input":"2024-10-28T08:31:49.975495Z","iopub.status.idle":"2024-10-28T08:31:50.059950Z","shell.execute_reply.started":"2024-10-28T08:31:49.975452Z","shell.execute_reply":"2024-10-28T08:31:50.059008Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"ID_code    0.0\ntarget     0.0\nvar_0      0.0\nvar_1      0.0\nvar_2      0.0\n          ... \nvar_195    0.0\nvar_196    0.0\nvar_197    0.0\nvar_198    0.0\nvar_199    0.0\nLength: 202, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"num_col=train.select_dtypes(exclude='object').columns.tolist()\nlen(num_col) # no object columns ","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:51.174638Z","iopub.execute_input":"2024-10-28T08:31:51.175010Z","iopub.status.idle":"2024-10-28T08:31:51.292152Z","shell.execute_reply.started":"2024-10-28T08:31:51.174973Z","shell.execute_reply":"2024-10-28T08:31:51.291249Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"201"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.model_selection import train_test_split \nfrom sklearn import metrics ","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:54.093627Z","iopub.execute_input":"2024-10-28T08:31:54.094018Z","iopub.status.idle":"2024-10-28T08:31:54.814346Z","shell.execute_reply.started":"2024-10-28T08:31:54.093979Z","shell.execute_reply":"2024-10-28T08:31:54.813528Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"X=train.drop(columns=['ID_code','target'])\ny=train['target']\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:56.390318Z","iopub.execute_input":"2024-10-28T08:31:56.391357Z","iopub.status.idle":"2024-10-28T08:31:56.487868Z","shell.execute_reply.started":"2024-10-28T08:31:56.391313Z","shell.execute_reply":"2024-10-28T08:31:56.486719Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:58.118481Z","iopub.execute_input":"2024-10-28T08:31:58.119379Z","iopub.status.idle":"2024-10-28T08:31:58.395846Z","shell.execute_reply.started":"2024-10-28T08:31:58.119338Z","shell.execute_reply":"2024-10-28T08:31:58.394825Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:31:59.817843Z","iopub.execute_input":"2024-10-28T08:31:59.818810Z","iopub.status.idle":"2024-10-28T08:31:59.824089Z","shell.execute_reply.started":"2024-10-28T08:31:59.818764Z","shell.execute_reply":"2024-10-28T08:31:59.823220Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"((160000, 200), (40000, 200))"},"metadata":{}}]},{"cell_type":"code","source":"# Select the top 2 features using ANOVA F-test\nselector = SelectKBest(score_func=f_classif, k=20)\nX_train_selected = selector.fit_transform(X_train, y_train)\nX_test_selected = selector.transform(X_test)\n\n# Get the selected feature names\nselected_features = X.columns[selector.get_support()]\nselected_features","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:02.799176Z","iopub.execute_input":"2024-10-28T08:32:02.799920Z","iopub.status.idle":"2024-10-28T08:32:03.270935Z","shell.execute_reply.started":"2024-10-28T08:32:02.799878Z","shell.execute_reply":"2024-10-28T08:32:03.269806Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Index(['var_2', 'var_6', 'var_12', 'var_13', 'var_21', 'var_22', 'var_26',\n       'var_53', 'var_76', 'var_80', 'var_81', 'var_99', 'var_110', 'var_133',\n       'var_139', 'var_146', 'var_165', 'var_166', 'var_174', 'var_190'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"X = X_train[selected_features]\n#X.head(2)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:05.072702Z","iopub.execute_input":"2024-10-28T08:32:05.073535Z","iopub.status.idle":"2024-10-28T08:32:05.090217Z","shell.execute_reply.started":"2024-10-28T08:32:05.073495Z","shell.execute_reply":"2024-10-28T08:32:05.089335Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(160000, 20)"},"metadata":{}}]},{"cell_type":"code","source":"min_samples = min(len(X), len(y))\nX = X[:min_samples]\ny = y[:min_samples]\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:06.692096Z","iopub.execute_input":"2024-10-28T08:32:06.692956Z","iopub.status.idle":"2024-10-28T08:32:06.697611Z","shell.execute_reply.started":"2024-10-28T08:32:06.692916Z","shell.execute_reply":"2024-10-28T08:32:06.696621Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:08.188808Z","iopub.execute_input":"2024-10-28T08:32:08.189453Z","iopub.status.idle":"2024-10-28T08:32:08.195677Z","shell.execute_reply.started":"2024-10-28T08:32:08.189413Z","shell.execute_reply":"2024-10-28T08:32:08.194717Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(160000,)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.33,stratify=y, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:09.884273Z","iopub.execute_input":"2024-10-28T08:32:09.884702Z","iopub.status.idle":"2024-10-28T08:32:09.975322Z","shell.execute_reply.started":"2024-10-28T08:32:09.884660Z","shell.execute_reply":"2024-10-28T08:32:09.974521Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!pip show h2o\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:11.199072Z","iopub.execute_input":"2024-10-28T08:32:11.199455Z","iopub.status.idle":"2024-10-28T08:32:22.728035Z","shell.execute_reply.started":"2024-10-28T08:32:11.199418Z","shell.execute_reply":"2024-10-28T08:32:22.726933Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Name: h2o\nVersion: 3.46.0.5\nSummary: H2O, Fast Scalable Machine Learning, for python \nHome-page: https://github.com/h2oai/h2o-3.git\nAuthor: H2O.ai\nAuthor-email: support@h2o.ai\nLicense: Apache v2\nLocation: /opt/conda/lib/python3.10/site-packages\nRequires: requests, tabulate\nRequired-by: \n","output_type":"stream"}]},{"cell_type":"code","source":"import h2o\nfrom h2o.automl import H2OAutoML\nh2o.init()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:22.730308Z","iopub.execute_input":"2024-10-28T08:32:22.731073Z","iopub.status.idle":"2024-10-28T08:32:30.301196Z","shell.execute_reply.started":"2024-10-28T08:32:22.731024Z","shell.execute_reply":"2024-10-28T08:32:30.300142Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Checking whether there is an H2O instance running at http://localhost:54321..... not found.\nAttempting to start a local H2O server...\n  Java Version: openjdk version \"11.0.24\" 2024-07-16; OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu322.04); OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu322.04, mixed mode, sharing)\n  Starting server from /opt/conda/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n  Ice root: /tmp/tmp311wkllh\n  JVM stdout: /tmp/tmp311wkllh/h2o_unknownUser_started_from_python.out\n  JVM stderr: /tmp/tmp311wkllh/h2o_unknownUser_started_from_python.err\n  Server is running at http://127.0.0.1:54321\nConnecting to H2O server at http://127.0.0.1:54321 ... successful.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ----------------------------------\nH2O_cluster_uptime:         02 secs\nH2O_cluster_timezone:       Etc/UTC\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.46.0.5\nH2O_cluster_version_age:    1 month and 28 days\nH2O_cluster_name:           H2O_from_python_unknownUser_yknmed\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    7.250 Gb\nH2O_cluster_total_cores:    4\nH2O_cluster_allowed_cores:  4\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.10.14 final\n--------------------------  ----------------------------------","text/html":"\n<style>\n\n#h2o-table-1.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-1 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-1 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-1 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-1 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-1 .h2o-table th,\n#h2o-table-1 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-1 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-1\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>02 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.46.0.5</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>1 month and 28 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_unknownUser_yknmed</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>7.250 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.10.14 final</td></tr></tbody>\n  </table>\n</div>\n"},"metadata":{}}]},{"cell_type":"code","source":"train_h2o = h2o.H2OFrame(pd.concat([X_train, y_train], axis=1))\nX_val = h2o.H2OFrame(X_val)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:32:30.303489Z","iopub.execute_input":"2024-10-28T08:32:30.304168Z","iopub.status.idle":"2024-10-28T08:32:38.657693Z","shell.execute_reply.started":"2024-10-28T08:32:30.304123Z","shell.execute_reply":"2024-10-28T08:32:38.656496Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\nParse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n","output_type":"stream"}]},{"cell_type":"code","source":"train_h2o = train_h2o.na_omit()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:59:02.544118Z","iopub.execute_input":"2024-10-28T08:59:02.544846Z","iopub.status.idle":"2024-10-28T08:59:02.549212Z","shell.execute_reply.started":"2024-10-28T08:59:02.544806Z","shell.execute_reply":"2024-10-28T08:59:02.548099Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(train_h2o['target'].isna().sum())\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:59:05.393154Z","iopub.execute_input":"2024-10-28T08:59:05.393574Z","iopub.status.idle":"2024-10-28T08:59:05.704343Z","shell.execute_reply.started":"2024-10-28T08:59:05.393534Z","shell.execute_reply":"2024-10-28T08:59:05.703294Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"target = 'target'\nfeatures = X.columns.tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:59:08.736976Z","iopub.execute_input":"2024-10-28T08:59:08.737842Z","iopub.status.idle":"2024-10-28T08:59:08.741981Z","shell.execute_reply.started":"2024-10-28T08:59:08.737803Z","shell.execute_reply":"2024-10-28T08:59:08.740967Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"train_h2o[target] = train_h2o[target].asfactor()","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:59:12.301353Z","iopub.execute_input":"2024-10-28T08:59:12.301775Z","iopub.status.idle":"2024-10-28T08:59:12.306845Z","shell.execute_reply.started":"2024-10-28T08:59:12.301735Z","shell.execute_reply":"2024-10-28T08:59:12.305896Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"automl = H2OAutoML(\n        max_models = 20,\n        seed = 42,\n        sort_metric = 'AUC',\n        include_algos = [\"GBM\", \"XGBoost\", \"GLM\", \"StackedEnsemble\", \"DRF\"],\n        balance_classes = True,\n        nfolds = 5)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:59:13.805706Z","iopub.execute_input":"2024-10-28T08:59:13.806428Z","iopub.status.idle":"2024-10-28T08:59:13.817426Z","shell.execute_reply.started":"2024-10-28T08:59:13.806388Z","shell.execute_reply":"2024-10-28T08:59:13.816482Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"automl.train(x=features, y=target, training_frame=train_h2o)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T08:59:15.081951Z","iopub.execute_input":"2024-10-28T08:59:15.082361Z","iopub.status.idle":"2024-10-28T09:12:41.867917Z","shell.execute_reply.started":"2024-10-28T08:59:15.082320Z","shell.execute_reply":"2024-10-28T09:12:41.867003Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"AutoML progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Model Details\n=============\nH2OStackedEnsembleEstimator : Stacked Ensemble\nModel Key: StackedEnsemble_AllModels_1_AutoML_2_20241028_85915\n\n\nModel Summary for Stacked Ensemble: \nkey                                   value\n------------------------------------  ----------------\nStacking strategy                     cross_validation\nNumber of base models (used / total)  9/20\n# GBM base models (used / total)      1/8\n# XGBoost base models (used / total)  7/9\n# GLM base models (used / total)      1/1\n# DRF base models (used / total)      0/2\nMetalearner algorithm                 GLM\nMetalearner fold assignment scheme    Random\nMetalearner nfolds                    5\nMetalearner fold_column\nCustom metalearner hyperparameters    None\n\nModelMetricsBinomialGLM: stackedensemble\n** Reported on train data. **\n\nMSE: 0.07338733771016409\nRMSE: 0.2709009739926457\nLogLoss: 0.25684701085820427\nAUC: 0.8319291939186931\nAUCPR: 0.46812584314138056\nGini: 0.6638583878373863\nNull degrees of freedom: 9977\nResidual degrees of freedom: 9968\nNull deviance: 6629.876663500007\nResidual deviance: 5125.6389486863245\nAIC: 5145.6389486863245\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.2059872030340583\n       0     1     Error    Rate\n-----  ----  ----  -------  ---------------\n0      8372  576   0.0644   (576.0/8948.0)\n1      524   506   0.5087   (524.0/1030.0)\nTotal  8896  1082  0.1102   (1100.0/9978.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.205987     0.479167  178\nmax f2                       0.119461     0.550076  249\nmax f0point5                 0.295355     0.51089   127\nmax accuracy                 0.343925     0.909802  107\nmax precision                0.946176     1         0\nmax recall                   0.012327     1         397\nmax specificity              0.946176     1         0\nmax absolute_mcc             0.205987     0.417721  178\nmax min_per_class_accuracy   0.103724     0.748544  266\nmax mean_per_class_accuracy  0.108032     0.755279  261\nmax tns                      0.946176     8948      0\nmax fns                      0.946176     1029      0\nmax fps                      0.0101751    8948      399\nmax tps                      0.012327     1030      397\nmax tnr                      0.946176     1         0\nmax fnr                      0.946176     0.999029  0\nmax fpr                      0.0101751    1         399\nmax tpr                      0.012327     1         397\n\nGains/Lift Table: Avg response rate: 10.32 %, avg score: 10.04 %\ngroup    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.010022                    0.537661           8.23427    8.23427            0.85             0.677815   0.85                        0.677815            0.0825243       0.0825243                  723.427   723.427            0.0808479\n2        0.0200441                   0.440253           6.58742    7.41084            0.68             0.48753    0.765                       0.582672            0.0660194       0.148544                   558.742   641.084            0.143291\n3        0.0300661                   0.373237           5.61868    6.81346            0.58             0.406545   0.703333                    0.523963            0.0563107       0.204854                   461.868   581.346            0.194908\n4        0.0400882                   0.333314           5.03744    6.36945            0.52             0.352078   0.6575                      0.480992            0.0504854       0.25534                    403.744   536.945            0.240029\n5        0.05001                     0.30324            4.40335    5.97938            0.454545         0.318248   0.617234                    0.448704            0.0436893       0.299029                   340.335   497.938            0.277684\n6        0.10002                     0.216737           3.30031    4.63985            0.340681         0.254164   0.478958                    0.351434            0.165049        0.464078                   230.031   363.985            0.405964\n7        0.15003                     0.166576           1.94136    3.74035            0.200401         0.190002   0.386106                    0.297623            0.0970874       0.561165                   94.1358   274.035            0.458461\n8        0.20004                     0.137693           1.68898    3.22751            0.174349         0.150802   0.333166                    0.260918            0.084466        0.645631                   68.8982   222.751            0.496883\n9        0.30006                     0.103263           1.02892    2.49465            0.106212         0.118791   0.257515                    0.213542            0.102913        0.748544                   2.892     149.465            0.500108\n10       0.39998                     0.0815974          0.72874    2.0535             0.0752257        0.0914938  0.211977                    0.183053            0.0728155       0.821359                   -27.126   105.35             0.469884\n11       0.5                         0.0662495          0.553287   1.7534             0.0571142        0.0734647  0.180998                    0.161131            0.0553398       0.876699                   -44.6713  75.3398            0.420061\n12       0.60002                     0.0539729          0.475633   1.5404             0.0490982        0.0600766  0.159011                    0.144286            0.0475728       0.924272                   -52.4367  54.0402            0.361576\n13       0.69994                     0.043658           0.320645   1.36628            0.0330993        0.0484973  0.141037                    0.130612            0.0320388       0.956311                   -67.9355  36.6275            0.285882\n14       0.79996                     0.0347581          0.232963   1.22458            0.0240481        0.0391341  0.126409                    0.119174            0.023301        0.979612                   -76.7037  22.4576            0.200331\n15       0.89998                     0.0263558          0.165015   1.10682            0.0170341        0.0306162  0.114254                    0.109332            0.0165049       0.996117                   -83.4985  10.6821            0.107203\n16       1                           0.00922422         0.0388272  1                  0.00400802       0.0203265  0.103227                    0.10043             0.0038835       1                          -96.1173  0                  0\n\nModelMetricsBinomialGLM: stackedensemble\n** Reported on cross-validation data. **\n\nMSE: 0.07845564166757663\nRMSE: 0.28009934249758\nLogLoss: 0.2776163105496577\nAUC: 0.7606885346426044\nAUCPR: 0.3198002930589842\nGini: 0.5213770692852089\nNull degrees of freedom: 57466\nResidual degrees of freedom: 57457\nNull deviance: 37064.51801187615\nResidual deviance: 31907.55303671436\nAIC: 31927.55303671436\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.17581944931634558\n       0      1     Error    Rate\n-----  -----  ----  -------  ----------------\n0      46267  5522  0.1066   (5522.0/51789.0)\n1      3257   2421  0.5736   (3257.0/5678.0)\nTotal  49524  7943  0.1528   (8779.0/57467.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.175819     0.355481  211\nmax f2                       0.0951558    0.46392   280\nmax f0point5                 0.310772     0.372826  134\nmax accuracy                 0.500495     0.904258  69\nmax precision                0.970061     1         0\nmax recall                   0.00969988   1         399\nmax specificity              0.970061     1         0\nmax absolute_mcc             0.175819     0.276463  211\nmax min_per_class_accuracy   0.0922978    0.692673  283\nmax mean_per_class_accuracy  0.0951558    0.694686  280\nmax tns                      0.970061     51789     0\nmax fns                      0.970061     5676      0\nmax fps                      0.00969988   51789     399\nmax tps                      0.00969988   5678      399\nmax tnr                      0.970061     1         0\nmax fnr                      0.970061     0.999648  0\nmax fpr                      0.00969988   1         399\nmax tpr                      0.00969988   1         399\n\nGains/Lift Table: Avg response rate:  9.88 %, avg score:  9.88 %\ngroup    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.0100057                   0.520828           6.53024   6.53024            0.645217         0.644753   0.645217                    0.644753            0.0653399       0.0653399                  553.024   553.024            0.0614008\n2        0.0200115                   0.425917           5.0869    5.80857            0.502609         0.468142   0.573913                    0.556448            0.0508982       0.116238                   408.69    480.857            0.106777\n3        0.0299998                   0.364826           4.09072   5.23662            0.404181         0.391887   0.517401                    0.501658            0.0408595       0.157098                   309.072   423.662            0.141032\n4        0.0400056                   0.325324           3.57315   4.82057            0.353043         0.344326   0.476294                    0.462308            0.035752        0.19285                    257.315   382.057            0.169601\n5        0.0500113                   0.29526            3.13311   4.48296            0.309565         0.309715   0.442937                    0.431779            0.0313491       0.224199                   213.311   348.296            0.193285\n6        0.100005                    0.210775           2.44834   3.46583            0.241907         0.247606   0.34244                     0.339708            0.122402        0.346601                   144.834   246.583            0.273632\n7        0.149999                    0.166592           1.93754   2.95646            0.191438         0.187106   0.292111                    0.288847            0.0968651       0.443466                   93.7538   195.646            0.325642\n8        0.20001                     0.138174           1.58471   2.61346            0.156576         0.151289   0.258222                    0.254452            0.0792533       0.522719                   58.4707   161.346            0.35809\n9        0.299998                    0.102632           1.25412   2.1604             0.123912         0.118686   0.213457                    0.209202            0.125396        0.648116                   25.4115   116.04             0.386284\n10       0.400003                    0.0808299          0.933379  1.85363            0.092222         0.0909353  0.183147                    0.179634            0.0933427       0.741458                   -6.66215  85.363             0.378891\n11       0.500009                    0.0653716          0.720286  1.62695            0.0711676        0.0727062  0.16075                     0.158248            0.0720324       0.813491                   -27.9714  62.6953            0.347851\n12       0.599997                    0.0531197          0.563647  1.44976            0.0556909        0.0589505  0.143242                    0.1417              0.0563579       0.869849                   -43.6353  44.9756            0.299438\n13       0.700002                    0.0434278          0.461406  1.30856            0.045589         0.0481512  0.129291                    0.128335            0.046143        0.915992                   -53.8594  30.8556            0.23967\n14       0.79999                     0.0346084          0.364609  1.19058            0.0360251        0.0389308  0.117634                    0.117161            0.0364565       0.952448                   -63.5391  19.0576            0.169174\n15       0.899995                    0.0260123          0.281775  1.08959            0.0278406        0.0303532  0.107657                    0.107515            0.0281789       0.980627                   -71.8225  8.95919            0.0894725\n16       1                           0.00649996         0.19372   1                  0.0191404        0.0203379  0.0988045                   0.0987968           0.019373        1                          -80.628   0                  0\n\nCross-Validation Metrics Summary: \n                      mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n--------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------\naccuracy              0.8481693    0.016881641   0.85055673    0.8701242     0.822775      0.8468492     0.8505416\naic                   6401.0254    199.97795     6167.266      6379.571      6680.884      6503.2383     6274.1685\nauc                   0.7608647    0.009228207   0.7623491     0.7583821     0.76238745    0.7477606     0.7734439\nerr                   0.15183064   0.016881641   0.14944328    0.12987576    0.177225      0.15315078    0.14945842\nerr_count             1745.6       201.85341     1718.0        1495.0        2059.0        1745.0        1711.0\nf0point5              0.3262872    0.011087834   0.3202202     0.34176996    0.3137149     0.32275712    0.33297384\nf1                    0.35635823   0.00761487    0.35703593    0.34687635    0.36075753    0.35105988    0.3660615\nf2                    0.39424118   0.027406348   0.40341678    0.35213766    0.42439738    0.38480353    0.40645054\nlift_top_group        6.480453     0.37423685    6.942029      6.0464406     6.165096      6.5296626     6.719036\nloglikelihood         0.0          0.0           0.0           0.0           0.0           0.0           0.0\n---                   ---          ---           ---           ---           ---           ---           ---\nmean_per_class_error  0.3399893    0.012871682   0.3326901     0.35945827    0.32829988    0.3465918     0.33290642\nmse                   0.07845372   0.002719072   0.074752025   0.07804644    0.0817863     0.080307774   0.077376045\nnull_deviance         7412.904     218.61136     7168.4844     7329.3115     7760.0767     7446.4663     7360.179\npr_auc                0.32053626   0.0130443415  0.31972516    0.30005717    0.3305969     0.3192119     0.33309007\nprecision             0.30940795   0.01872368    0.2996231     0.33844844    0.28862396    0.30629462    0.3140496\nr2                    0.118728474  0.0075398153  0.12180342    0.1085633     0.12213927    0.11363255    0.12750384\nrecall                0.42564654   0.04632766    0.44166666    0.35573477    0.48096028    0.41114983    0.43872115\nresidual_deviance     6381.4253    201.25334     6147.266      6359.571      6662.884      6485.2383     6252.1685\nrmse                  0.28006217   0.004859563   0.27340817    0.27936792    0.28598303    0.28338626    0.2781655\nspecificity           0.8943749    0.02227161    0.89295316    0.9253487     0.86244       0.8956666     0.89546597\n[24 rows x 8 columns]\n\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.","text/html":"<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OStackedEnsembleEstimator : Stacked Ensemble\nModel Key: StackedEnsemble_AllModels_1_AutoML_2_20241028_85915\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-10.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-10 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-10 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-10 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-10 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-10 .h2o-table th,\n#h2o-table-10 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-10 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-10\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Model Summary for Stacked Ensemble: </caption>\n    <thead><tr><th>key</th>\n<th>value</th></tr></thead>\n    <tbody><tr><td>Stacking strategy</td>\n<td>cross_validation</td></tr>\n<tr><td>Number of base models (used / total)</td>\n<td>9/20</td></tr>\n<tr><td># GBM base models (used / total)</td>\n<td>1/8</td></tr>\n<tr><td># XGBoost base models (used / total)</td>\n<td>7/9</td></tr>\n<tr><td># GLM base models (used / total)</td>\n<td>1/1</td></tr>\n<tr><td># DRF base models (used / total)</td>\n<td>0/2</td></tr>\n<tr><td>Metalearner algorithm</td>\n<td>GLM</td></tr>\n<tr><td>Metalearner fold assignment scheme</td>\n<td>Random</td></tr>\n<tr><td>Metalearner nfolds</td>\n<td>5</td></tr>\n<tr><td>Metalearner fold_column</td>\n<td>None</td></tr>\n<tr><td>Custom metalearner hyperparameters</td>\n<td>None</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n** Reported on train data. **\n\nMSE: 0.07338733771016409\nRMSE: 0.2709009739926457\nLogLoss: 0.25684701085820427\nAUC: 0.8319291939186931\nAUCPR: 0.46812584314138056\nGini: 0.6638583878373863\nNull degrees of freedom: 9977\nResidual degrees of freedom: 9968\nNull deviance: 6629.876663500007\nResidual deviance: 5125.6389486863245\nAIC: 5145.6389486863245</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-11.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-11 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-11 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-11 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-11 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-11 .h2o-table th,\n#h2o-table-11 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-11 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-11\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2059872030340583</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>8372.0</td>\n<td>576.0</td>\n<td>0.0644</td>\n<td> (576.0/8948.0)</td></tr>\n<tr><td>1</td>\n<td>524.0</td>\n<td>506.0</td>\n<td>0.5087</td>\n<td> (524.0/1030.0)</td></tr>\n<tr><td>Total</td>\n<td>8896.0</td>\n<td>1082.0</td>\n<td>0.1102</td>\n<td> (1100.0/9978.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-12.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-12 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-12 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-12 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-12 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-12 .h2o-table th,\n#h2o-table-12 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-12 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-12\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.2059872</td>\n<td>0.4791667</td>\n<td>178.0</td></tr>\n<tr><td>max f2</td>\n<td>0.1194612</td>\n<td>0.5500759</td>\n<td>249.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.2953553</td>\n<td>0.5108905</td>\n<td>127.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.3439255</td>\n<td>0.9098016</td>\n<td>107.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9461762</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.0123270</td>\n<td>1.0</td>\n<td>397.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9461762</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.2059872</td>\n<td>0.4177215</td>\n<td>178.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.1037245</td>\n<td>0.7485437</td>\n<td>266.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.1080320</td>\n<td>0.7552788</td>\n<td>261.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9461762</td>\n<td>8948.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9461762</td>\n<td>1029.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0101751</td>\n<td>8948.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.0123270</td>\n<td>1030.0</td>\n<td>397.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9461762</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9461762</td>\n<td>0.9990291</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0101751</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.0123270</td>\n<td>1.0</td>\n<td>397.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-13.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-13 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-13 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-13 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-13 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-13 .h2o-table th,\n#h2o-table-13 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-13 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-13\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 10.32 %, avg score: 10.04 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0100220</td>\n<td>0.5376605</td>\n<td>8.2342718</td>\n<td>8.2342718</td>\n<td>0.85</td>\n<td>0.6778150</td>\n<td>0.85</td>\n<td>0.6778150</td>\n<td>0.0825243</td>\n<td>0.0825243</td>\n<td>723.4271845</td>\n<td>723.4271845</td>\n<td>0.0808479</td></tr>\n<tr><td>2</td>\n<td>0.0200441</td>\n<td>0.4402532</td>\n<td>6.5874175</td>\n<td>7.4108447</td>\n<td>0.68</td>\n<td>0.4875299</td>\n<td>0.765</td>\n<td>0.5826724</td>\n<td>0.0660194</td>\n<td>0.1485437</td>\n<td>558.7417476</td>\n<td>641.0844660</td>\n<td>0.1432911</td></tr>\n<tr><td>3</td>\n<td>0.0300661</td>\n<td>0.3732374</td>\n<td>5.6186796</td>\n<td>6.8134563</td>\n<td>0.58</td>\n<td>0.4065445</td>\n<td>0.7033333</td>\n<td>0.5239631</td>\n<td>0.0563107</td>\n<td>0.2048544</td>\n<td>461.8679612</td>\n<td>581.3456311</td>\n<td>0.1949080</td></tr>\n<tr><td>4</td>\n<td>0.0400882</td>\n<td>0.3333144</td>\n<td>5.0374369</td>\n<td>6.3694515</td>\n<td>0.52</td>\n<td>0.3520780</td>\n<td>0.6575</td>\n<td>0.4809918</td>\n<td>0.0504854</td>\n<td>0.2553398</td>\n<td>403.7436893</td>\n<td>536.9451456</td>\n<td>0.2400291</td></tr>\n<tr><td>5</td>\n<td>0.0500100</td>\n<td>0.3032401</td>\n<td>4.4033539</td>\n<td>5.9793840</td>\n<td>0.4545455</td>\n<td>0.3182479</td>\n<td>0.6172345</td>\n<td>0.4487040</td>\n<td>0.0436893</td>\n<td>0.2990291</td>\n<td>340.3353928</td>\n<td>497.9384011</td>\n<td>0.2776836</td></tr>\n<tr><td>6</td>\n<td>0.1000200</td>\n<td>0.2167374</td>\n<td>3.3003094</td>\n<td>4.6398467</td>\n<td>0.3406814</td>\n<td>0.2541639</td>\n<td>0.4789579</td>\n<td>0.3514339</td>\n<td>0.1650485</td>\n<td>0.4640777</td>\n<td>230.0309357</td>\n<td>363.9846684</td>\n<td>0.4059641</td></tr>\n<tr><td>7</td>\n<td>0.1500301</td>\n<td>0.1665764</td>\n<td>1.9413584</td>\n<td>3.7403506</td>\n<td>0.2004008</td>\n<td>0.1900017</td>\n<td>0.3861055</td>\n<td>0.2976232</td>\n<td>0.0970874</td>\n<td>0.5611650</td>\n<td>94.1358445</td>\n<td>274.0350604</td>\n<td>0.4584605</td></tr>\n<tr><td>8</td>\n<td>0.2000401</td>\n<td>0.1376934</td>\n<td>1.6889818</td>\n<td>3.2275084</td>\n<td>0.1743487</td>\n<td>0.1508018</td>\n<td>0.3331663</td>\n<td>0.2609178</td>\n<td>0.0844660</td>\n<td>0.6456311</td>\n<td>68.8981847</td>\n<td>222.7508415</td>\n<td>0.4968827</td></tr>\n<tr><td>9</td>\n<td>0.3000601</td>\n<td>0.1032630</td>\n<td>1.0289200</td>\n<td>2.4946456</td>\n<td>0.1062124</td>\n<td>0.1187911</td>\n<td>0.2575150</td>\n<td>0.2135423</td>\n<td>0.1029126</td>\n<td>0.7485437</td>\n<td>2.8919976</td>\n<td>149.4645602</td>\n<td>0.5001083</td></tr>\n<tr><td>10</td>\n<td>0.3999800</td>\n<td>0.0815974</td>\n<td>0.7287396</td>\n<td>2.0535010</td>\n<td>0.0752257</td>\n<td>0.0914938</td>\n<td>0.2119769</td>\n<td>0.1830531</td>\n<td>0.0728155</td>\n<td>0.8213592</td>\n<td>-27.1260383</td>\n<td>105.3500960</td>\n<td>0.4698840</td></tr>\n<tr><td>11</td>\n<td>0.5</td>\n<td>0.0662495</td>\n<td>0.5532872</td>\n<td>1.7533981</td>\n<td>0.0571142</td>\n<td>0.0734647</td>\n<td>0.1809982</td>\n<td>0.1611310</td>\n<td>0.0553398</td>\n<td>0.8766990</td>\n<td>-44.6712843</td>\n<td>75.3398058</td>\n<td>0.4200607</td></tr>\n<tr><td>12</td>\n<td>0.6000200</td>\n<td>0.0539729</td>\n<td>0.4756328</td>\n<td>1.5404016</td>\n<td>0.0490982</td>\n<td>0.0600766</td>\n<td>0.1590112</td>\n<td>0.1442858</td>\n<td>0.0475728</td>\n<td>0.9242718</td>\n<td>-52.4367181</td>\n<td>54.0401615</td>\n<td>0.3615763</td></tr>\n<tr><td>13</td>\n<td>0.6999399</td>\n<td>0.0436580</td>\n<td>0.3206454</td>\n<td>1.3662755</td>\n<td>0.0330993</td>\n<td>0.0484973</td>\n<td>0.1410367</td>\n<td>0.1306115</td>\n<td>0.0320388</td>\n<td>0.9563107</td>\n<td>-67.9354569</td>\n<td>36.6275481</td>\n<td>0.2858815</td></tr>\n<tr><td>14</td>\n<td>0.7999599</td>\n<td>0.0347581</td>\n<td>0.2329630</td>\n<td>1.2245759</td>\n<td>0.0240481</td>\n<td>0.0391341</td>\n<td>0.1264094</td>\n<td>0.1191740</td>\n<td>0.0233010</td>\n<td>0.9796117</td>\n<td>-76.7036987</td>\n<td>22.4575927</td>\n<td>0.2003314</td></tr>\n<tr><td>15</td>\n<td>0.8999800</td>\n<td>0.0263558</td>\n<td>0.1650155</td>\n<td>1.1068208</td>\n<td>0.0170341</td>\n<td>0.0306162</td>\n<td>0.1142539</td>\n<td>0.1093320</td>\n<td>0.0165049</td>\n<td>0.9961165</td>\n<td>-83.4984532</td>\n<td>10.6820767</td>\n<td>0.1072028</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0092242</td>\n<td>0.0388272</td>\n<td>1.0</td>\n<td>0.0040080</td>\n<td>0.0203265</td>\n<td>0.1032271</td>\n<td>0.1004297</td>\n<td>0.0038835</td>\n<td>1.0</td>\n<td>-96.1172831</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomialGLM: stackedensemble\n** Reported on cross-validation data. **\n\nMSE: 0.07845564166757663\nRMSE: 0.28009934249758\nLogLoss: 0.2776163105496577\nAUC: 0.7606885346426044\nAUCPR: 0.3198002930589842\nGini: 0.5213770692852089\nNull degrees of freedom: 57466\nResidual degrees of freedom: 57457\nNull deviance: 37064.51801187615\nResidual deviance: 31907.55303671436\nAIC: 31927.55303671436</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-14.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-14 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-14 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-14 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-14 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-14 .h2o-table th,\n#h2o-table-14 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-14 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-14\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.17581944931634558</caption>\n    <thead><tr><th></th>\n<th>0</th>\n<th>1</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>0</td>\n<td>46267.0</td>\n<td>5522.0</td>\n<td>0.1066</td>\n<td> (5522.0/51789.0)</td></tr>\n<tr><td>1</td>\n<td>3257.0</td>\n<td>2421.0</td>\n<td>0.5736</td>\n<td> (3257.0/5678.0)</td></tr>\n<tr><td>Total</td>\n<td>49524.0</td>\n<td>7943.0</td>\n<td>0.1528</td>\n<td> (8779.0/57467.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-15.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-15 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-15 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-15 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-15 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-15 .h2o-table th,\n#h2o-table-15 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-15 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-15\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.1758194</td>\n<td>0.3554805</td>\n<td>211.0</td></tr>\n<tr><td>max f2</td>\n<td>0.0951558</td>\n<td>0.4639200</td>\n<td>280.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.3107717</td>\n<td>0.3728262</td>\n<td>134.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.5004950</td>\n<td>0.9042581</td>\n<td>69.0</td></tr>\n<tr><td>max precision</td>\n<td>0.9700610</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.0096999</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.9700610</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.1758194</td>\n<td>0.2764631</td>\n<td>211.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.0922978</td>\n<td>0.6926735</td>\n<td>283.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.0951558</td>\n<td>0.6946862</td>\n<td>280.0</td></tr>\n<tr><td>max tns</td>\n<td>0.9700610</td>\n<td>51789.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.9700610</td>\n<td>5676.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.0096999</td>\n<td>51789.0</td>\n<td>399.0</td></tr>\n<tr><td>max tps</td>\n<td>0.0096999</td>\n<td>5678.0</td>\n<td>399.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.9700610</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.9700610</td>\n<td>0.9996478</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.0096999</td>\n<td>1.0</td>\n<td>399.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.0096999</td>\n<td>1.0</td>\n<td>399.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-16.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-16 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-16 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-16 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-16 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-16 .h2o-table th,\n#h2o-table-16 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-16 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-16\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate:  9.88 %, avg score:  9.88 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0100057</td>\n<td>0.5208282</td>\n<td>6.5302409</td>\n<td>6.5302409</td>\n<td>0.6452174</td>\n<td>0.6447534</td>\n<td>0.6452174</td>\n<td>0.6447534</td>\n<td>0.0653399</td>\n<td>0.0653399</td>\n<td>553.0240899</td>\n<td>553.0240899</td>\n<td>0.0614008</td></tr>\n<tr><td>2</td>\n<td>0.0200115</td>\n<td>0.4259173</td>\n<td>5.0868992</td>\n<td>5.8085701</td>\n<td>0.5026087</td>\n<td>0.4681424</td>\n<td>0.5739130</td>\n<td>0.5564479</td>\n<td>0.0508982</td>\n<td>0.1162381</td>\n<td>408.6899245</td>\n<td>480.8570072</td>\n<td>0.1067766</td></tr>\n<tr><td>3</td>\n<td>0.0299998</td>\n<td>0.3648264</td>\n<td>4.0907151</td>\n<td>5.2366160</td>\n<td>0.4041812</td>\n<td>0.3918866</td>\n<td>0.5174014</td>\n<td>0.5016578</td>\n<td>0.0408595</td>\n<td>0.1570976</td>\n<td>309.0715065</td>\n<td>423.6616027</td>\n<td>0.1410324</td></tr>\n<tr><td>4</td>\n<td>0.0400056</td>\n<td>0.3253239</td>\n<td>3.5731507</td>\n<td>4.8205688</td>\n<td>0.3530435</td>\n<td>0.3443257</td>\n<td>0.4762940</td>\n<td>0.4623076</td>\n<td>0.0357520</td>\n<td>0.1928496</td>\n<td>257.3150681</td>\n<td>382.0568800</td>\n<td>0.1696014</td></tr>\n<tr><td>5</td>\n<td>0.0500113</td>\n<td>0.2952601</td>\n<td>3.1331075</td>\n<td>4.4829591</td>\n<td>0.3095652</td>\n<td>0.3097152</td>\n<td>0.4429367</td>\n<td>0.4317785</td>\n<td>0.0313491</td>\n<td>0.2241987</td>\n<td>213.3107493</td>\n<td>348.2959109</td>\n<td>0.1932848</td></tr>\n<tr><td>6</td>\n<td>0.1000052</td>\n<td>0.2107749</td>\n<td>2.4483433</td>\n<td>3.4658282</td>\n<td>0.2419074</td>\n<td>0.2476064</td>\n<td>0.3424395</td>\n<td>0.3397085</td>\n<td>0.1224023</td>\n<td>0.3466009</td>\n<td>144.8343317</td>\n<td>246.5828228</td>\n<td>0.2736318</td></tr>\n<tr><td>7</td>\n<td>0.1499991</td>\n<td>0.1665915</td>\n<td>1.9375379</td>\n<td>2.9564572</td>\n<td>0.1914375</td>\n<td>0.1871064</td>\n<td>0.2921114</td>\n<td>0.2888470</td>\n<td>0.0968651</td>\n<td>0.4434660</td>\n<td>93.7537876</td>\n<td>195.6457210</td>\n<td>0.3256418</td></tr>\n<tr><td>8</td>\n<td>0.2000104</td>\n<td>0.1381739</td>\n<td>1.5847067</td>\n<td>2.6134599</td>\n<td>0.1565762</td>\n<td>0.1512890</td>\n<td>0.2582217</td>\n<td>0.2544515</td>\n<td>0.0792533</td>\n<td>0.5227193</td>\n<td>58.4706677</td>\n<td>161.3459904</td>\n<td>0.3580897</td></tr>\n<tr><td>9</td>\n<td>0.2999983</td>\n<td>0.1026316</td>\n<td>1.2541154</td>\n<td>2.1603976</td>\n<td>0.1239123</td>\n<td>0.1186862</td>\n<td>0.2134571</td>\n<td>0.2092017</td>\n<td>0.1253963</td>\n<td>0.6481155</td>\n<td>25.4115426</td>\n<td>116.0397643</td>\n<td>0.3862839</td></tr>\n<tr><td>10</td>\n<td>0.4000035</td>\n<td>0.0808299</td>\n<td>0.9333785</td>\n<td>1.8536295</td>\n<td>0.0922220</td>\n<td>0.0909353</td>\n<td>0.1831470</td>\n<td>0.1796338</td>\n<td>0.0933427</td>\n<td>0.7414583</td>\n<td>-6.6621463</td>\n<td>85.3629522</td>\n<td>0.3788909</td></tr>\n<tr><td>11</td>\n<td>0.5000087</td>\n<td>0.0653716</td>\n<td>0.7202865</td>\n<td>1.6269530</td>\n<td>0.0711676</td>\n<td>0.0727062</td>\n<td>0.1607503</td>\n<td>0.1582475</td>\n<td>0.0720324</td>\n<td>0.8134907</td>\n<td>-27.9713544</td>\n<td>62.6953020</td>\n<td>0.3478512</td></tr>\n<tr><td>12</td>\n<td>0.5999965</td>\n<td>0.0531197</td>\n<td>0.5636474</td>\n<td>1.4497560</td>\n<td>0.0556909</td>\n<td>0.0589505</td>\n<td>0.1432425</td>\n<td>0.1416999</td>\n<td>0.0563579</td>\n<td>0.8698485</td>\n<td>-43.6352618</td>\n<td>44.9755973</td>\n<td>0.2994378</td></tr>\n<tr><td>13</td>\n<td>0.7000017</td>\n<td>0.0434278</td>\n<td>0.4614060</td>\n<td>1.3085561</td>\n<td>0.0455890</td>\n<td>0.0481512</td>\n<td>0.1292913</td>\n<td>0.1283352</td>\n<td>0.0461430</td>\n<td>0.9159915</td>\n<td>-53.8594006</td>\n<td>30.8556099</td>\n<td>0.2396703</td></tr>\n<tr><td>14</td>\n<td>0.7999896</td>\n<td>0.0346084</td>\n<td>0.3646094</td>\n<td>1.1905756</td>\n<td>0.0360251</td>\n<td>0.0389308</td>\n<td>0.1176343</td>\n<td>0.1171608</td>\n<td>0.0364565</td>\n<td>0.9524480</td>\n<td>-63.5390600</td>\n<td>19.0575595</td>\n<td>0.1691736</td></tr>\n<tr><td>15</td>\n<td>0.8999948</td>\n<td>0.0260123</td>\n<td>0.2817747</td>\n<td>1.0895919</td>\n<td>0.0278406</td>\n<td>0.0303532</td>\n<td>0.1076566</td>\n<td>0.1075150</td>\n<td>0.0281789</td>\n<td>0.9806270</td>\n<td>-71.8225347</td>\n<td>8.9591855</td>\n<td>0.0894725</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.0065000</td>\n<td>0.1937201</td>\n<td>1.0</td>\n<td>0.0191404</td>\n<td>0.0203379</td>\n<td>0.0988045</td>\n<td>0.0987968</td>\n<td>0.0193730</td>\n<td>1.0</td>\n<td>-80.6279926</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-17.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-17 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-17 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-17 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-17 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-17 .h2o-table th,\n#h2o-table-17 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-17 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-17\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Cross-Validation Metrics Summary: </caption>\n    <thead><tr><th></th>\n<th>mean</th>\n<th>sd</th>\n<th>cv_1_valid</th>\n<th>cv_2_valid</th>\n<th>cv_3_valid</th>\n<th>cv_4_valid</th>\n<th>cv_5_valid</th></tr></thead>\n    <tbody><tr><td>accuracy</td>\n<td>0.8481693</td>\n<td>0.0168816</td>\n<td>0.8505567</td>\n<td>0.8701242</td>\n<td>0.822775</td>\n<td>0.8468492</td>\n<td>0.8505416</td></tr>\n<tr><td>aic</td>\n<td>6401.0254</td>\n<td>199.97795</td>\n<td>6167.266</td>\n<td>6379.571</td>\n<td>6680.884</td>\n<td>6503.2383</td>\n<td>6274.1685</td></tr>\n<tr><td>auc</td>\n<td>0.7608647</td>\n<td>0.0092282</td>\n<td>0.7623491</td>\n<td>0.7583821</td>\n<td>0.7623874</td>\n<td>0.7477606</td>\n<td>0.7734439</td></tr>\n<tr><td>err</td>\n<td>0.1518306</td>\n<td>0.0168816</td>\n<td>0.1494433</td>\n<td>0.1298758</td>\n<td>0.177225</td>\n<td>0.1531508</td>\n<td>0.1494584</td></tr>\n<tr><td>err_count</td>\n<td>1745.6</td>\n<td>201.85341</td>\n<td>1718.0</td>\n<td>1495.0</td>\n<td>2059.0</td>\n<td>1745.0</td>\n<td>1711.0</td></tr>\n<tr><td>f0point5</td>\n<td>0.3262872</td>\n<td>0.0110878</td>\n<td>0.3202202</td>\n<td>0.3417700</td>\n<td>0.3137149</td>\n<td>0.3227571</td>\n<td>0.3329738</td></tr>\n<tr><td>f1</td>\n<td>0.3563582</td>\n<td>0.0076149</td>\n<td>0.3570359</td>\n<td>0.3468763</td>\n<td>0.3607575</td>\n<td>0.3510599</td>\n<td>0.3660615</td></tr>\n<tr><td>f2</td>\n<td>0.3942412</td>\n<td>0.0274063</td>\n<td>0.4034168</td>\n<td>0.3521377</td>\n<td>0.4243974</td>\n<td>0.3848035</td>\n<td>0.4064505</td></tr>\n<tr><td>lift_top_group</td>\n<td>6.480453</td>\n<td>0.3742369</td>\n<td>6.942029</td>\n<td>6.0464406</td>\n<td>6.165096</td>\n<td>6.5296626</td>\n<td>6.719036</td></tr>\n<tr><td>loglikelihood</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.0</td></tr>\n<tr><td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td>\n<td>---</td></tr>\n<tr><td>mean_per_class_error</td>\n<td>0.3399893</td>\n<td>0.0128717</td>\n<td>0.3326901</td>\n<td>0.3594583</td>\n<td>0.3282999</td>\n<td>0.3465918</td>\n<td>0.3329064</td></tr>\n<tr><td>mse</td>\n<td>0.0784537</td>\n<td>0.0027191</td>\n<td>0.0747520</td>\n<td>0.0780464</td>\n<td>0.0817863</td>\n<td>0.0803078</td>\n<td>0.0773760</td></tr>\n<tr><td>null_deviance</td>\n<td>7412.904</td>\n<td>218.61136</td>\n<td>7168.4844</td>\n<td>7329.3115</td>\n<td>7760.0767</td>\n<td>7446.4663</td>\n<td>7360.179</td></tr>\n<tr><td>pr_auc</td>\n<td>0.3205363</td>\n<td>0.0130443</td>\n<td>0.3197252</td>\n<td>0.3000572</td>\n<td>0.3305969</td>\n<td>0.3192119</td>\n<td>0.3330901</td></tr>\n<tr><td>precision</td>\n<td>0.3094079</td>\n<td>0.0187237</td>\n<td>0.2996231</td>\n<td>0.3384484</td>\n<td>0.2886240</td>\n<td>0.3062946</td>\n<td>0.3140496</td></tr>\n<tr><td>r2</td>\n<td>0.1187285</td>\n<td>0.0075398</td>\n<td>0.1218034</td>\n<td>0.1085633</td>\n<td>0.1221393</td>\n<td>0.1136325</td>\n<td>0.1275038</td></tr>\n<tr><td>recall</td>\n<td>0.4256465</td>\n<td>0.0463277</td>\n<td>0.4416667</td>\n<td>0.3557348</td>\n<td>0.4809603</td>\n<td>0.4111498</td>\n<td>0.4387212</td></tr>\n<tr><td>residual_deviance</td>\n<td>6381.4253</td>\n<td>201.25334</td>\n<td>6147.266</td>\n<td>6359.571</td>\n<td>6662.884</td>\n<td>6485.2383</td>\n<td>6252.1685</td></tr>\n<tr><td>rmse</td>\n<td>0.2800622</td>\n<td>0.0048596</td>\n<td>0.2734082</td>\n<td>0.2793679</td>\n<td>0.2859830</td>\n<td>0.2833863</td>\n<td>0.2781655</td></tr>\n<tr><td>specificity</td>\n<td>0.8943749</td>\n<td>0.0222716</td>\n<td>0.8929532</td>\n<td>0.9253487</td>\n<td>0.86244</td>\n<td>0.8956666</td>\n<td>0.8954660</td></tr></tbody>\n  </table>\n</div>\n<pre style='font-size: smaller; margin-bottom: 1em;'>[24 rows x 8 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"},"metadata":{}}]},{"cell_type":"code","source":"print(test.columns)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:20:42.673099Z","iopub.execute_input":"2024-10-28T09:20:42.673504Z","iopub.status.idle":"2024-10-28T09:20:42.678970Z","shell.execute_reply.started":"2024-10-28T09:20:42.673465Z","shell.execute_reply":"2024-10-28T09:20:42.677961Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Index(['ID_code', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5',\n       'var_6', 'var_7', 'var_8',\n       ...\n       'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',\n       'var_196', 'var_197', 'var_198', 'var_199'],\n      dtype='object', length=201)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test = test.drop(columns=['ID_code'])","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:21:04.866614Z","iopub.execute_input":"2024-10-28T09:21:04.867377Z","iopub.status.idle":"2024-10-28T09:21:04.966392Z","shell.execute_reply.started":"2024-10-28T09:21:04.867337Z","shell.execute_reply":"2024-10-28T09:21:04.965590Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"X_test= X_test[selected_features]","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:22:38.551460Z","iopub.execute_input":"2024-10-28T09:22:38.552503Z","iopub.status.idle":"2024-10-28T09:22:38.569827Z","shell.execute_reply.started":"2024-10-28T09:22:38.552460Z","shell.execute_reply":"2024-10-28T09:22:38.568835Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"X_test","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:22:44.786238Z","iopub.execute_input":"2024-10-28T09:22:44.786618Z","iopub.status.idle":"2024-10-28T09:22:44.818943Z","shell.execute_reply.started":"2024-10-28T09:22:44.786580Z","shell.execute_reply":"2024-10-28T09:22:44.817738Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"          var_2   var_6   var_12   var_13   var_21  var_22   var_26  var_53  \\\n0       12.9536  5.8493  13.9696   0.3458  18.8064  1.5899  -9.4902  7.3213   \n1       11.3047  6.0196  14.1129   2.5667   3.1389  5.2578  -5.2341  6.8481   \n2       10.1407  4.8950  13.6751   3.8183  12.3696  4.7473 -15.4246  5.6510   \n3       12.0220  4.9397  14.0526  13.5010  12.5527  2.9707   1.0061  6.2536   \n4       14.1295  6.8595  14.1013   8.9672  16.3059  6.7954   8.6228  5.6794   \n...         ...     ...      ...      ...      ...     ...      ...     ...   \n199995  10.4333  4.8579  14.3201  17.4594   9.8526  4.0207 -12.4547  6.4420   \n199996   7.3443  5.6888  13.8246   6.6547  16.6921  5.5064   0.0592  6.2642   \n199997  11.2074  5.3883  14.0675  13.9975  16.0286  0.6066  -9.1787  6.2427   \n199998  13.6584  4.1959  14.3051   4.2644  20.9599  1.1101   3.6157  4.9431   \n199999  10.2277  4.8879  13.8333   2.4590  15.5896 -2.1275  -2.7192  6.0381   \n\n         var_76   var_80   var_81  var_99  var_110  var_133  var_139  var_146  \\\n0        7.3075   9.4883  16.9060  1.8585   3.7662   7.5147  -2.5502  11.6793   \n1        6.9388   1.9772  14.0406 -1.4166   1.7375   7.0891   6.7530   8.7644   \n2       -9.7077  16.1691  14.3299  1.7818   8.6896   6.5950  -6.0452  11.6749   \n3       12.5465  17.5941  15.4375  2.6165  10.3445   6.7888  12.7898   8.6963   \n4        8.1522  11.8133  16.7661  0.1148   6.3933   7.1434  11.7989  12.9327   \n...         ...      ...      ...     ...      ...      ...      ...      ...   \n199995   7.6126   7.7879  13.9172 -2.3265   1.9588   6.9553  14.0376   8.0605   \n199996   7.8092  12.1609  15.5275 -2.0057   6.3677   6.6422  16.9374   9.9044   \n199997  -4.1993  12.0411  15.2880 -0.3975   0.2553   6.7956  16.5629  12.0198   \n199998  15.5314   2.3608   9.1805  0.3056  10.8259   7.0122   7.2125  10.3614   \n199999  -0.6072   8.0110  11.3898 -0.6401   3.3216   7.1313  -1.6528   9.8170   \n\n        var_165  var_166  var_174  var_190  \n0       22.9530   2.5531  18.1317  -2.1556  \n1       15.5134   3.2185  10.5018  10.6165  \n2       13.3009   3.1243  27.4035  -0.7484  \n3       24.8712   2.6415  14.5499   9.5702  \n4       26.2040   3.2348  14.0037   4.2259  \n...         ...      ...      ...      ...  \n199995  21.8848   3.5995  26.2206   2.0544  \n199996  18.2834   3.0946  20.1379   5.0071  \n199997  11.9434   3.2239  18.9432   5.1536  \n199998  20.1410   3.2078  13.2572   3.4259  \n199999  17.1152   2.4527  30.1926   0.1398  \n\n[200000 rows x 20 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var_2</th>\n      <th>var_6</th>\n      <th>var_12</th>\n      <th>var_13</th>\n      <th>var_21</th>\n      <th>var_22</th>\n      <th>var_26</th>\n      <th>var_53</th>\n      <th>var_76</th>\n      <th>var_80</th>\n      <th>var_81</th>\n      <th>var_99</th>\n      <th>var_110</th>\n      <th>var_133</th>\n      <th>var_139</th>\n      <th>var_146</th>\n      <th>var_165</th>\n      <th>var_166</th>\n      <th>var_174</th>\n      <th>var_190</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.9536</td>\n      <td>5.8493</td>\n      <td>13.9696</td>\n      <td>0.3458</td>\n      <td>18.8064</td>\n      <td>1.5899</td>\n      <td>-9.4902</td>\n      <td>7.3213</td>\n      <td>7.3075</td>\n      <td>9.4883</td>\n      <td>16.9060</td>\n      <td>1.8585</td>\n      <td>3.7662</td>\n      <td>7.5147</td>\n      <td>-2.5502</td>\n      <td>11.6793</td>\n      <td>22.9530</td>\n      <td>2.5531</td>\n      <td>18.1317</td>\n      <td>-2.1556</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11.3047</td>\n      <td>6.0196</td>\n      <td>14.1129</td>\n      <td>2.5667</td>\n      <td>3.1389</td>\n      <td>5.2578</td>\n      <td>-5.2341</td>\n      <td>6.8481</td>\n      <td>6.9388</td>\n      <td>1.9772</td>\n      <td>14.0406</td>\n      <td>-1.4166</td>\n      <td>1.7375</td>\n      <td>7.0891</td>\n      <td>6.7530</td>\n      <td>8.7644</td>\n      <td>15.5134</td>\n      <td>3.2185</td>\n      <td>10.5018</td>\n      <td>10.6165</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.1407</td>\n      <td>4.8950</td>\n      <td>13.6751</td>\n      <td>3.8183</td>\n      <td>12.3696</td>\n      <td>4.7473</td>\n      <td>-15.4246</td>\n      <td>5.6510</td>\n      <td>-9.7077</td>\n      <td>16.1691</td>\n      <td>14.3299</td>\n      <td>1.7818</td>\n      <td>8.6896</td>\n      <td>6.5950</td>\n      <td>-6.0452</td>\n      <td>11.6749</td>\n      <td>13.3009</td>\n      <td>3.1243</td>\n      <td>27.4035</td>\n      <td>-0.7484</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.0220</td>\n      <td>4.9397</td>\n      <td>14.0526</td>\n      <td>13.5010</td>\n      <td>12.5527</td>\n      <td>2.9707</td>\n      <td>1.0061</td>\n      <td>6.2536</td>\n      <td>12.5465</td>\n      <td>17.5941</td>\n      <td>15.4375</td>\n      <td>2.6165</td>\n      <td>10.3445</td>\n      <td>6.7888</td>\n      <td>12.7898</td>\n      <td>8.6963</td>\n      <td>24.8712</td>\n      <td>2.6415</td>\n      <td>14.5499</td>\n      <td>9.5702</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14.1295</td>\n      <td>6.8595</td>\n      <td>14.1013</td>\n      <td>8.9672</td>\n      <td>16.3059</td>\n      <td>6.7954</td>\n      <td>8.6228</td>\n      <td>5.6794</td>\n      <td>8.1522</td>\n      <td>11.8133</td>\n      <td>16.7661</td>\n      <td>0.1148</td>\n      <td>6.3933</td>\n      <td>7.1434</td>\n      <td>11.7989</td>\n      <td>12.9327</td>\n      <td>26.2040</td>\n      <td>3.2348</td>\n      <td>14.0037</td>\n      <td>4.2259</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>10.4333</td>\n      <td>4.8579</td>\n      <td>14.3201</td>\n      <td>17.4594</td>\n      <td>9.8526</td>\n      <td>4.0207</td>\n      <td>-12.4547</td>\n      <td>6.4420</td>\n      <td>7.6126</td>\n      <td>7.7879</td>\n      <td>13.9172</td>\n      <td>-2.3265</td>\n      <td>1.9588</td>\n      <td>6.9553</td>\n      <td>14.0376</td>\n      <td>8.0605</td>\n      <td>21.8848</td>\n      <td>3.5995</td>\n      <td>26.2206</td>\n      <td>2.0544</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>7.3443</td>\n      <td>5.6888</td>\n      <td>13.8246</td>\n      <td>6.6547</td>\n      <td>16.6921</td>\n      <td>5.5064</td>\n      <td>0.0592</td>\n      <td>6.2642</td>\n      <td>7.8092</td>\n      <td>12.1609</td>\n      <td>15.5275</td>\n      <td>-2.0057</td>\n      <td>6.3677</td>\n      <td>6.6422</td>\n      <td>16.9374</td>\n      <td>9.9044</td>\n      <td>18.2834</td>\n      <td>3.0946</td>\n      <td>20.1379</td>\n      <td>5.0071</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>11.2074</td>\n      <td>5.3883</td>\n      <td>14.0675</td>\n      <td>13.9975</td>\n      <td>16.0286</td>\n      <td>0.6066</td>\n      <td>-9.1787</td>\n      <td>6.2427</td>\n      <td>-4.1993</td>\n      <td>12.0411</td>\n      <td>15.2880</td>\n      <td>-0.3975</td>\n      <td>0.2553</td>\n      <td>6.7956</td>\n      <td>16.5629</td>\n      <td>12.0198</td>\n      <td>11.9434</td>\n      <td>3.2239</td>\n      <td>18.9432</td>\n      <td>5.1536</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>13.6584</td>\n      <td>4.1959</td>\n      <td>14.3051</td>\n      <td>4.2644</td>\n      <td>20.9599</td>\n      <td>1.1101</td>\n      <td>3.6157</td>\n      <td>4.9431</td>\n      <td>15.5314</td>\n      <td>2.3608</td>\n      <td>9.1805</td>\n      <td>0.3056</td>\n      <td>10.8259</td>\n      <td>7.0122</td>\n      <td>7.2125</td>\n      <td>10.3614</td>\n      <td>20.1410</td>\n      <td>3.2078</td>\n      <td>13.2572</td>\n      <td>3.4259</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>10.2277</td>\n      <td>4.8879</td>\n      <td>13.8333</td>\n      <td>2.4590</td>\n      <td>15.5896</td>\n      <td>-2.1275</td>\n      <td>-2.7192</td>\n      <td>6.0381</td>\n      <td>-0.6072</td>\n      <td>8.0110</td>\n      <td>11.3898</td>\n      <td>-0.6401</td>\n      <td>3.3216</td>\n      <td>7.1313</td>\n      <td>-1.6528</td>\n      <td>9.8170</td>\n      <td>17.1152</td>\n      <td>2.4527</td>\n      <td>30.1926</td>\n      <td>0.1398</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows Ã— 20 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_h2o = h2o.H2OFrame(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:23:47.676336Z","iopub.execute_input":"2024-10-28T09:23:47.677105Z","iopub.status.idle":"2024-10-28T09:23:53.424595Z","shell.execute_reply.started":"2024-10-28T09:23:47.677064Z","shell.execute_reply":"2024-10-28T09:23:53.423442Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Parse progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model = automl.leader\npredictions = best_model.predict(test_h2o)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:24:12.990720Z","iopub.execute_input":"2024-10-28T09:24:12.991107Z","iopub.status.idle":"2024-10-28T09:24:17.436987Z","shell.execute_reply.started":"2024-10-28T09:24:12.991070Z","shell.execute_reply":"2024-10-28T09:24:17.436027Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"stackedensemble prediction progress: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| (done) 100%\n","output_type":"stream"}]},{"cell_type":"code","source":"output = predictions.as_data_frame()\noutput","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:24:31.087246Z","iopub.execute_input":"2024-10-28T09:24:31.087632Z","iopub.status.idle":"2024-10-28T09:24:31.507085Z","shell.execute_reply.started":"2024-10-28T09:24:31.087594Z","shell.execute_reply":"2024-10-28T09:24:31.506064Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/h2o/frame.py:1981: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n\n  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"        predict        p0        p1\n0             0  0.837023  0.162977\n1             0  0.867935  0.132065\n2             0  0.859046  0.140954\n3             0  0.927896  0.072104\n4             0  0.890644  0.109356\n...         ...       ...       ...\n199995        0  0.982940  0.017060\n199996        0  0.967539  0.032461\n199997        0  0.981287  0.018713\n199998        0  0.884084  0.115916\n199999        0  0.914010  0.085990\n\n[200000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predict</th>\n      <th>p0</th>\n      <th>p1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.837023</td>\n      <td>0.162977</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.867935</td>\n      <td>0.132065</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.859046</td>\n      <td>0.140954</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.927896</td>\n      <td>0.072104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.890644</td>\n      <td>0.109356</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>0</td>\n      <td>0.982940</td>\n      <td>0.017060</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>0</td>\n      <td>0.967539</td>\n      <td>0.032461</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>0</td>\n      <td>0.981287</td>\n      <td>0.018713</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>0</td>\n      <td>0.884084</td>\n      <td>0.115916</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>0</td>\n      <td>0.914010</td>\n      <td>0.085990</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(len(submission), len(predictions))\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:30:19.885164Z","iopub.execute_input":"2024-10-28T09:30:19.885544Z","iopub.status.idle":"2024-10-28T09:30:19.890783Z","shell.execute_reply.started":"2024-10-28T09:30:19.885510Z","shell.execute_reply":"2024-10-28T09:30:19.889928Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"200000 200000\n","output_type":"stream"}]},{"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/sample_submission.csv\")\n\n# Assuming 'predictions' is already a pandas DataFrame at this stage\n# Apply threshold and assign to submission file\nsubmission['target'] = (predictions['p1'] > 0.5).astype(int)\n\n# Display the head of the submission DataFrame\nsubmission.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:31:01.318780Z","iopub.execute_input":"2024-10-28T09:31:01.319196Z","iopub.status.idle":"2024-10-28T09:31:01.428738Z","shell.execute_reply.started":"2024-10-28T09:31:01.319155Z","shell.execute_reply":"2024-10-28T09:31:01.427746Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"  ID_code  target\n0  test_0       0\n1  test_1       0\n2  test_2       0\n3  test_3       0\n4  test_4       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID_code</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T09:32:43.286577Z","iopub.execute_input":"2024-10-28T09:32:43.287660Z","iopub.status.idle":"2024-10-28T09:32:43.567237Z","shell.execute_reply.started":"2024-10-28T09:32:43.287607Z","shell.execute_reply":"2024-10-28T09:32:43.566352Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}